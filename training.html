

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Training &mdash; OpenNMT-tf 1.10.0 documentation</title>
  

  
  
    <link rel="shortcut icon" href="_static/favicon.png"/>
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Inference" href="inference.html" />
    <link rel="prev" title="Configuration" href="configuration.html" /> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> OpenNMT-tf
          

          
            
            <img src="_static/logo-alpha.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                1.10
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="quickstart.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="data.html">Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="tokenization.html">Tokenization</a></li>
<li class="toctree-l1"><a class="reference internal" href="configuration.html">Configuration</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Training</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#monitoring">Monitoring</a></li>
<li class="toctree-l2"><a class="reference internal" href="#replicated-training">Replicated training</a></li>
<li class="toctree-l2"><a class="reference internal" href="#distributed-training">Distributed training</a></li>
<li class="toctree-l2"><a class="reference internal" href="#mixed-precision-training">Mixed precision training</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="inference.html">Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="serving.html">Serving</a></li>
<li class="toctree-l1"><a class="reference internal" href="configuration_reference.html">Reference: Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="package/opennmt.html">Reference: opennmt package</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">OpenNMT-tf</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Training</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="training">
<span id="training"></span><h1>Training<a class="headerlink" href="#training" title="Permalink to this headline">¶</a></h1>
<div class="section" id="monitoring">
<span id="monitoring"></span><h2>Monitoring<a class="headerlink" href="#monitoring" title="Permalink to this headline">¶</a></h2>
<p>OpenNMT-tf uses <a class="reference external" href="https://github.com/tensorflow/tensorboard">TensorBoard</a> to log information during the training. Simply start <code class="docutils literal notranslate"><span class="pre">tensorboard</span></code> by setting the active log directory, e.g.:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>tensorboard --logdir<span class="o">=</span><span class="s2">&quot;.&quot;</span>
</pre></div>
</div>
<p>then open the URL displayed in the shell to monitor and visualize several data, including:</p>
<ul class="simple">
<li>training and evaluation loss</li>
<li>training speed</li>
<li>learning rate</li>
<li>gradients norm</li>
<li>computation graphs</li>
<li>word embeddings</li>
<li>decoder sampling probability</li>
</ul>
</div>
<div class="section" id="replicated-training">
<span id="replicated-training"></span><h2>Replicated training<a class="headerlink" href="#replicated-training" title="Permalink to this headline">¶</a></h2>
<p>OpenNMT-tf training can make use of multiple GPUs with <em>in-graph replication</em>. In this mode, the main section of the graph is replicated over multiple devices and batches are processed in parallel. The resulting graph is equivalent to train with batches <code class="docutils literal notranslate"><span class="pre">N</span></code> times larger, where <code class="docutils literal notranslate"><span class="pre">N</span></code> is the number of used GPUs.</p>
<p>For example, if your machine has 4 GPUs, simply add the <code class="docutils literal notranslate"><span class="pre">--num_gpus</span></code> option:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>onmt-main train <span class="o">[</span>...<span class="o">]</span> --num_gpus <span class="m">4</span>
</pre></div>
</div>
<p>Note that evaluation and inference will run on a single device.</p>
</div>
<div class="section" id="distributed-training">
<span id="distributed-training"></span><h2>Distributed training<a class="headerlink" href="#distributed-training" title="Permalink to this headline">¶</a></h2>
<p>OpenNMT-tf also supports asynchronous distributed training with <em>between-graph replication</em>. In this mode, each graph replica processes a batch independently, compute the gradients, and asynchronously update a shared set of parameters.</p>
<p>To enable distributed training, the user should use the <code class="docutils literal notranslate"><span class="pre">train_and_eval</span></code> run type and set on the command line:</p>
<ul class="simple">
<li>a <strong>chief worker</strong> host that runs a training loop and manages checkpoints, summaries, etc.</li>
<li>a list of <strong>worker</strong> hosts that run a training loop</li>
<li>a list of <strong>parameter server</strong> hosts that synchronize the parameters</li>
</ul>
<p>Then a training instance should be started on each host with a selected task, e.g.:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span> onmt-main train_and_eval <span class="o">[</span>...<span class="o">]</span> <span class="se">\</span>
    --ps_hosts localhost:2222 <span class="se">\</span>
    --chief_host localhost:2223 <span class="se">\</span>
    --worker_hosts localhost:2224,localhost:2225 <span class="se">\</span>
    --task_type worker <span class="se">\</span>
    --task_index <span class="m">1</span>
</pre></div>
</div>
<p>will start the worker 1 on the current machine and first GPU. By setting <code class="docutils literal notranslate"><span class="pre">CUDA_VISIBLE_DEVICES</span></code> correctly, asynchronous distributed training can be run on a single multi-GPU machine.</p>
<p>For more details, see the documentation of <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/estimator/train_and_evaluate"><code class="docutils literal notranslate"><span class="pre">tf.estimator.train_and_evaluate</span></code></a>. Also see <a class="reference external" href="https://github.com/tensorflow/ecosystem">tensorflow/ecosystem</a> to integrate distributed training with open-source frameworks like Docker or Kubernetes.</p>
<p><strong>Note:</strong> distributed training will also split the training directory <code class="docutils literal notranslate"><span class="pre">model_dir</span></code> accross the instances. This could impact features that restore checkpoints like inference, manual export, or checkpoint averaging. The recommend approach to properly support these features while running distributed training is to store the <code class="docutils literal notranslate"><span class="pre">model_dir</span></code> on a shared filesystem, e.g. by using <a class="reference external" href="https://www.tensorflow.org/deploy/hadoop">HDFS</a>.</p>
</div>
<div class="section" id="mixed-precision-training">
<span id="mixed-precision-training"></span><h2>Mixed precision training<a class="headerlink" href="#mixed-precision-training" title="Permalink to this headline">¶</a></h2>
<p>Thanks to <a class="reference external" href="https://github.com/NVIDIA/OpenSeq2Seq">work from NVIDIA</a>, OpenNMT-tf supports training models using FP16 computation. Mixed precision training is automatically enabled when the data type of the <a class="reference external" href="package/opennmt.inputters.inputter.html">inputters</a> is defined to be <code class="docutils literal notranslate"><span class="pre">tf.float16</span></code>. See for example the predefined model <code class="docutils literal notranslate"><span class="pre">TransformerFP16</span></code>:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>onmt-main train <span class="o">[</span>...<span class="o">]</span> --model_type TransformerFP16
</pre></div>
</div>
<p>Additional training configurations are available to tune the loss scaling algorithm:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">params</span><span class="p p-Indicator">:</span>
  <span class="c1"># (optional) For mixed precision training, the loss scaling to apply (a constant value or</span>
  <span class="c1"># an automatic scaling algorithm: &quot;backoff&quot;, &quot;logmax&quot;, default: &quot;backoff&quot;)</span>
  <span class="l l-Scalar l-Scalar-Plain">loss_scale</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">backoff</span>
  <span class="c1"># (optional) For mixed precision training, the additional parameters to pass the loss scale</span>
  <span class="c1"># (see the source file opennmt/optimizers/mixed_precision_wrapper.py).</span>
  <span class="l l-Scalar l-Scalar-Plain">loss_scale_params</span><span class="p p-Indicator">:</span>
    <span class="l l-Scalar l-Scalar-Plain">scale_min</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">1.0</span>
    <span class="l l-Scalar l-Scalar-Plain">step_factor</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">2.0</span>
</pre></div>
</div>
<p>For more information about the implementation and get expert recommendation on how to maximize performance, see the <a class="reference external" href="https://nvidia.github.io/OpenSeq2Seq/html/mixed-precision.html">OpenSeq2Seq’s documentation</a>. Currently, mixed precision training requires Volta GPUs and the NVIDIA’s TensorFlow Docker image.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="inference.html" class="btn btn-neutral float-right" title="Inference" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="configuration.html" class="btn btn-neutral" title="Configuration" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, The OpenNMT Authors

    </p>
  </div> 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    
    
      <script type="text/javascript">
          var DOCUMENTATION_OPTIONS = {
              URL_ROOT:'./',
              VERSION:'1.10.0',
              LANGUAGE:'en',
              COLLAPSE_INDEX:false,
              FILE_SUFFIX:'.html',
              HAS_SOURCE:  true,
              SOURCELINK_SUFFIX: '.txt'
          };
      </script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    

  

  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>